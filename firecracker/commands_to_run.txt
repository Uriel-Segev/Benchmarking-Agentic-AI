================================================================================
FIRECRACKER BENCHMARKING - COMMANDS & WORKFLOW
================================================================================

All scripts are in Benchmarking-Agentic-AI/firecracker/scripts/


--------------------------------------------------------------------------------
SCRIPT OVERVIEW
--------------------------------------------------------------------------------

One-time setup (run once per machine):
  install_firecracker.sh    - Installs firecracker binary, TAP networking, iptables
  setup_base_rootfs.sh      - Creates base Ubuntu 22.04 ext4 rootfs disk image

Building blocks (called automatically, you don't run these directly):
  prepare_task_rootfs.sh    - Installs python/deps into rootfs for a task
                              (called by run_parallel.sh when given a task directory)
  run_task.sh               - Launches a single Firecracker VM
                              (called by run_parallel.sh for each instance)
  run_parallel.sh           - Launches N VMs in parallel, collects results
                              (called by both scaling scripts)

What you actually run for benchmarks:
  run_scaling.sh            - Powers of 2 (1, 2, 4, 8, 16, 32, ...)
  run_scaling_linear.sh     - Linear increments (10, 20, 30, 40, ...)
  run_bottleneck.sh         - Fine-grained sweep around CPU saturation point


--------------------------------------------------------------------------------
STEP 1: MACHINE VERIFICATION
--------------------------------------------------------------------------------

hostname
lsb_release -a || cat /etc/os-release
uname -r
ls -l /dev/kvm


--------------------------------------------------------------------------------
STEP 2: ONE-TIME SETUP
--------------------------------------------------------------------------------

# Make all scripts executable
chmod +x Benchmarking-Agentic-AI/firecracker/scripts/*.sh

# Dry run to verify setup
sudo DRY_RUN=1 Benchmarking-Agentic-AI/firecracker/scripts/install_firecracker.sh

# Install firecracker and networking
sudo ROOTFS_URL="https://s3.amazonaws.com/spec.ccfc.min/firecracker-ci/v1.9/$(uname -m)/ubuntu-22.04.ext4" \
     KERNEL_URL="https://s3.amazonaws.com/spec.ccfc.min/firecracker-ci/v1.9/$(uname -m)/vmlinux-5.10.225" \
     Benchmarking-Agentic-AI/firecracker/scripts/install_firecracker.sh

# Verify networking
ip a | grep -E "tap0|192\.168\.100\.1" -n
ip route | head

# Create base rootfs
sudo Benchmarking-Agentic-AI/firecracker/scripts/setup_base_rootfs.sh

# Install sysstat (needed for monitoring during bottleneck runs)
sudo apt-get update && sudo apt-get install -y sysstat


--------------------------------------------------------------------------------
STEP 3: PREPARE TASK ROOTFS (once per task)
--------------------------------------------------------------------------------

# Build the rootfs for a task (only needed once, reuse the .ext4 file after)
# Tasks live in Benchmarking-Agentic-AI/tasks/ — no terminal-bench clone needed.

# hello-world (baseline, no extra deps)
sudo Benchmarking-Agentic-AI/firecracker/scripts/prepare_task_rootfs.sh \
    Benchmarking-Agentic-AI/tasks/hello-world \
    /opt/firecracker/rootfs-hello-world.ext4

# parallelize-compute-squares (no extra deps)
sudo Benchmarking-Agentic-AI/firecracker/scripts/prepare_task_rootfs.sh \
    Benchmarking-Agentic-AI/tasks/parallelize-compute-squares \
    /opt/firecracker/rootfs-parallelize-compute-squares.ext4

# pytorch-model-recovery (installs torch CPU ~200MB — needs extra disk space)
sudo EXTRA_SPACE=3G Benchmarking-Agentic-AI/firecracker/scripts/prepare_task_rootfs.sh \
    Benchmarking-Agentic-AI/tasks/pytorch-model-recovery \
    /opt/firecracker/rootfs-pytorch-model-recovery.ext4

# hf-model-inference (installs transformers+flask+torch, downloads ~250MB distilbert model)
sudo EXTRA_SPACE=3G Benchmarking-Agentic-AI/firecracker/scripts/prepare_task_rootfs.sh \
    Benchmarking-Agentic-AI/tasks/hf-model-inference \
    /opt/firecracker/rootfs-hf-model-inference.ext4

# Each command creates a named .ext4 file — pass that to the scaling/bottleneck scripts
# to avoid re-installing deps every run.


--------------------------------------------------------------------------------
STEP 4: RUN BENCHMARKS
--------------------------------------------------------------------------------

# --label sets the experiment label (used to organize results in ~/results/)
# Results are auto-saved to ~/results/<task>/firecracker/<label>/<timestamp>/

# Bottleneck analysis (custom VM counts around CPU saturation point, with host monitoring)
sudo Benchmarking-Agentic-AI/firecracker/scripts/run_bottleneck.sh \
  /opt/firecracker/rootfs-parallelize-compute-squares.ext4 \
  --label 16c

sudo Benchmarking-Agentic-AI/firecracker/scripts/run_bottleneck.sh \
  /opt/firecracker/rootfs-pytorch-model-recovery.ext4 \
  --label 16c

sudo Benchmarking-Agentic-AI/firecracker/scripts/run_bottleneck.sh \
  /opt/firecracker/rootfs-hf-model-inference.ext4 \
  --label 16c

# Exponential scaling (powers of 2): 1, 2, 4, 8, 16, 32, 64
sudo Benchmarking-Agentic-AI/firecracker/scripts/run_scaling.sh \
    /opt/firecracker/rootfs-parallelize-compute-squares.ext4 64 \
    --label 16c \
    --repeats 5 \
    --cooldown 10

# Linear scaling (increments of 10): 10, 20, 30, 40, ..., 100
sudo Benchmarking-Agentic-AI/firecracker/scripts/run_scaling_linear.sh \
    /opt/firecracker/rootfs-parallelize-compute-squares.ext4 100 \
    --label 16c \
    --repeats 5 \
    --cooldown 10

# Resume a failed/interrupted run (pass --output with the interrupted run's JSON path)
sudo Benchmarking-Agentic-AI/firecracker/scripts/run_scaling.sh \
  /opt/firecracker/rootfs-parallelize-compute-squares.ext4 64 \
  --label 16c \
  --cooldown 10 \
  --resume \
  --output ~/results/parallelize-compute-squares/firecracker/16c/<timestamp>/scaling.json


--------------------------------------------------------------------------------
STEP 5: COPY RESULTS TO LOCAL MACHINE
--------------------------------------------------------------------------------

# Run from your local machine (PowerShell), not from node0
# Results are organized by task / hypervisor / label — copy what you need:

# Copy all results for a task:
scp -r -i ~/.ssh/id_ed25519 NAME@IP:~/results/parallelize-compute-squares/ .

# Copy a specific label (e.g. 16c):
scp -r -i ~/.ssh/id_ed25519 NAME@IP:~/results/parallelize-compute-squares/firecracker/16c/ .

# to get ip: hostname -I


--------------------------------------------------------------------------------
STEP 6: DISPLAY RESULTS
--------------------------------------------------------------------------------

# Run from local machine, generates bar charts with completion rate overlay
python display_json_time.py results/parallelize-compute-squares/firecracker/16c/<timestamp>/scaling.json

# Same display_json_time.py works for both Firecracker and Cloud Hypervisor results
# (identical JSON format — now includes machine: {hostname, logical_cpus, physical_cores, total_mem_mb})


--------------------------------------------------------------------------------
TIMING METRICS
--------------------------------------------------------------------------------

Per-instance timing breakdown:
  boot_time_s           - Host launch to guest autorun start
  solution_time_s       - solution.sh execution
  test_time_s           - pytest execution
  task_total_time_s     - Boot-done to pre-shutdown
  shutdown_time_s       - reboot -f to process exit
  total_vm_lifecycle_s  - Host launch to process exit

Aggregate stats (min/max/avg) are computed across all completed instances.


--------------------------------------------------------------------------------
RESULTS STRUCTURE
--------------------------------------------------------------------------------

Results are automatically organized as:
  ~/results/<task>/<hypervisor>/<label>/<timestamp>/
    scaling.json          (from run_scaling.sh or run_scaling_linear.sh)
    results.json          (from run_bottleneck.sh)
    bottleneck_logs/      (from run_bottleneck.sh)
      machine_info.txt
      vm1_repeat1_vmstat.log
      vm1_repeat1_iostat.log
      ...

The label is user-provided (e.g. "16c" for a 16-core machine).
The timestamp is auto-generated (YYYYMMDD_HHMMSS).


--------------------------------------------------------------------------------
NOTES
--------------------------------------------------------------------------------

- Each VM uses 2 vCPUs and 1024 MiB RAM by default
- Override with: sudo MEM_SIZE_MIB=512 VCPU_COUNT=1 ./scripts/run_scaling.sh ...
- With 48 cores, expect slowdown around 24+ VMs (48 vCPUs saturated)
- The "pip as root" warning during prepare is harmless (runs inside disposable rootfs)
- Pass the .ext4 rootfs file (not task directory) to avoid re-installing deps every run
