================================================================================
CLOUD HYPERVISOR BENCHMARKING - COMMANDS & WORKFLOW
================================================================================

All scripts are in Benchmarking-Agentic-AI/cloud-hypervisor/scripts/


--------------------------------------------------------------------------------
SCRIPT OVERVIEW
--------------------------------------------------------------------------------

One-time setup (run once per machine):
  install_cloud_hypervisor.sh - Installs cloud-hypervisor binary, TAP networking, iptables
  setup_base_rootfs.sh        - Creates base Ubuntu 22.04 ext4 rootfs disk image

Building blocks (called automatically, you don't run these directly):
  prepare_task_rootfs.sh    - Installs python/deps into rootfs for a task
                              (called by run_parallel.sh when given a task directory)
  run_task.sh               - Launches a single Cloud Hypervisor VM
                              (called by run_parallel.sh for each instance)
  run_parallel.sh           - Launches N VMs in parallel, collects results
                              (called by both scaling scripts)

What you actually run for benchmarks:
  run_scaling.sh            - Powers of 2 (1, 2, 4, 8, 16, 32, ...)
  run_scaling_linear.sh     - Linear increments (10, 20, 30, 40, ...)
  run_bottleneck.sh         - Fine-grained sweep around CPU saturation point


--------------------------------------------------------------------------------
STEP 1: MACHINE VERIFICATION
--------------------------------------------------------------------------------

hostname
lsb_release -a || cat /etc/os-release
uname -r
ls -l /dev/kvm


--------------------------------------------------------------------------------
STEP 2: ONE-TIME SETUP
--------------------------------------------------------------------------------

# Make all scripts executable
chmod +x Benchmarking-Agentic-AI/cloud-hypervisor/scripts/*.sh

# Dry run to verify setup
sudo DRY_RUN=1 Benchmarking-Agentic-AI/cloud-hypervisor/scripts/install_cloud_hypervisor.sh

# Install cloud-hypervisor and networking
sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/install_cloud_hypervisor.sh

# Verify networking
ip a | grep -E "tap0|192\.168\.100\.1" -n
ip route | head

# Create base rootfs
sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/setup_base_rootfs.sh

# Install sysstat (needed for monitoring during bottleneck runs)
sudo apt-get update && sudo apt-get install -y sysstat


--------------------------------------------------------------------------------
STEP 3: PREPARE TASK ROOTFS (once per task)
--------------------------------------------------------------------------------

# Build the rootfs for a task (only needed once, reuse the .ext4 file after)
# Tasks live in Benchmarking-Agentic-AI/tasks/ — no terminal-bench clone needed.

# hello-world (baseline, no extra deps)
sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/prepare_task_rootfs.sh \
    Benchmarking-Agentic-AI/tasks/hello-world \
    /opt/cloud-hypervisor/rootfs-hello-world.ext4

# parallelize-compute-squares (no extra deps)
sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/prepare_task_rootfs.sh \
    Benchmarking-Agentic-AI/tasks/parallelize-compute-squares \
    /opt/cloud-hypervisor/rootfs-parallelize-compute-squares.ext4

# pytorch-model-recovery (installs torch CPU ~200MB — needs extra disk space)
sudo EXTRA_SPACE=3G Benchmarking-Agentic-AI/cloud-hypervisor/scripts/prepare_task_rootfs.sh \
    Benchmarking-Agentic-AI/tasks/pytorch-model-recovery \
    /opt/cloud-hypervisor/rootfs-pytorch-model-recovery.ext4

# hf-model-inference (installs transformers+flask+torch, downloads ~250MB distilbert model)
sudo EXTRA_SPACE=3G Benchmarking-Agentic-AI/cloud-hypervisor/scripts/prepare_task_rootfs.sh \
    Benchmarking-Agentic-AI/tasks/hf-model-inference \
    /opt/cloud-hypervisor/rootfs-hf-model-inference.ext4

# Each command creates a named .ext4 file — pass that to the scaling/bottleneck scripts
# to avoid re-installing deps every run.


--------------------------------------------------------------------------------
STEP 4: RUN BENCHMARKS
--------------------------------------------------------------------------------

# --label sets the experiment label (used to organize results in ~/results/)
# Results are auto-saved to ~/results/<task>/cloud-hypervisor/<label>/<timestamp>/

# Bottleneck analysis (custom VM counts around CPU saturation point, with host monitoring)
sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/run_bottleneck.sh \
  /opt/cloud-hypervisor/rootfs-parallelize-compute-squares.ext4 \
  --label 48c

sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/run_bottleneck.sh \
  /opt/cloud-hypervisor/rootfs-pytorch-model-recovery.ext4 \
  --label 48c

sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/run_bottleneck.sh \
  /opt/cloud-hypervisor/rootfs-hf-model-inference.ext4 \
  --label 48c

# Exponential scaling (powers of 2): 1, 2, 4, 8, 16, 32, 64
sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/run_scaling.sh \
    /opt/cloud-hypervisor/rootfs-parallelize-compute-squares.ext4 64 \
    --label 48c \
    --repeats 5 \
    --cooldown 10

# Linear scaling (increments of 10): 10, 20, 30, 40, ..., 100
sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/run_scaling_linear.sh \
    /opt/cloud-hypervisor/rootfs-parallelize-compute-squares.ext4 100 \
    --label 48c \
    --repeats 5 \
    --cooldown 10

# Resume a failed/interrupted run (pass --output with the interrupted run's JSON path)
sudo Benchmarking-Agentic-AI/cloud-hypervisor/scripts/run_scaling.sh \
  /opt/cloud-hypervisor/rootfs-parallelize-compute-squares.ext4 64 \
  --label 48c \
  --cooldown 10 \
  --resume \
  --output ~/results/parallelize-compute-squares/cloud-hypervisor/48c/<timestamp>/scaling.json


--------------------------------------------------------------------------------
STEP 5: COPY RESULTS TO LOCAL MACHINE
--------------------------------------------------------------------------------

# Run from your local machine (PowerShell), not from node0
# Results are organized by task / hypervisor / label — copy what you need:

# Copy all results for a task:
scp -r -i ~/.ssh/id_ed25519 NAME@IP:~/results/parallelize-compute-squares/ .

# Copy a specific label (e.g. 48c):
scp -r -i ~/.ssh/id_ed25519 NAME@IP:~/results/parallelize-compute-squares/cloud-hypervisor/48c/ .

# to get ip: hostname -I


--------------------------------------------------------------------------------
STEP 6: DISPLAY RESULTS
--------------------------------------------------------------------------------

# Run from local machine, generates bar charts with completion rate overlay
python display_json_time.py results/parallelize-compute-squares/cloud-hypervisor/48c/<timestamp>/scaling.json

# Same display_json_time.py works for both Firecracker and Cloud Hypervisor results
# (identical JSON format — now includes machine: {hostname, logical_cpus, physical_cores, total_mem_mb})


--------------------------------------------------------------------------------
TIMING METRICS
--------------------------------------------------------------------------------

Per-instance timing breakdown:
  boot_time_s           - Host launch to guest autorun start
  solution_time_s       - solution.sh execution
  test_time_s           - pytest execution
  task_total_time_s     - Boot-done to pre-shutdown
  shutdown_time_s       - poweroff to process exit
  total_vm_lifecycle_s  - Host launch to process exit

Aggregate stats (min/max/avg) are computed across all completed instances.


--------------------------------------------------------------------------------
RESULTS STRUCTURE
--------------------------------------------------------------------------------

Results are automatically organized as:
  ~/results/<task>/<hypervisor>/<label>/<timestamp>/
    scaling.json          (from run_scaling.sh or run_scaling_linear.sh)
    results.json          (from run_bottleneck.sh)
    bottleneck_logs/      (from run_bottleneck.sh)
      machine_info.txt
      vm1_repeat1_vmstat.log
      vm1_repeat1_iostat.log
      ...

The label is user-provided (e.g. "48c" for a 48-core machine).
The timestamp is auto-generated (YYYYMMDD_HHMMSS).


--------------------------------------------------------------------------------
KEY DIFFERENCES FROM FIRECRACKER
--------------------------------------------------------------------------------

- VMM binary: cloud-hypervisor (not firecracker)
- Config: CLI flags (not JSON config file)
- Shutdown: guest uses "poweroff" (not "reboot -f")
- Kernel: host bzImage + initramfs (not custom vmlinux)
- WORKDIR: /opt/cloud-hypervisor (not /opt/firecracker)
- iptables chains: CH_NAT, CH_FWD (not FC_NAT, FC_FWD)
- Console: --serial tty + console=ttyS0 (same serial as Firecracker)
- JSON output format: IDENTICAL (same display_json_time.py works)


--------------------------------------------------------------------------------
NOTES
--------------------------------------------------------------------------------

- Each VM uses 2 vCPUs and 1024 MiB RAM by default
- Override with: sudo MEM_SIZE_MIB=512 VCPU_COUNT=1 ./scripts/run_scaling.sh ...
- With 48 cores, expect slowdown around 24+ VMs (48 vCPUs saturated)
- The "pip as root" warning during prepare is harmless (runs inside disposable rootfs)
- Pass the .ext4 rootfs file (not task directory) to avoid re-installing deps every run
- Cloud Hypervisor can run alongside Firecracker (different TAP chains, same subnets)


--------------------------------------------------------------------------------
OBSERVED PERFORMANCE (48-core CloudLab machine, hello-world task)
--------------------------------------------------------------------------------

- Baseline boot time: ~7.6s (vs Firecracker ~2-3s)
  This is due to full host kernel (bzImage + initramfs) vs Firecracker's stripped vmlinux
- 100% completion up to 16 VMs, drops to ~65% at 32 VMs, ~64% at 64 VMs
- Failed VMs exit with code 141 (SIGPIPE) — they timeout during boot under contention
- Increasing TASK_TIMEOUT would likely recover many failures (the actual task only takes ~1s)
- Total lifecycle: ~9s at low counts, ~13s at 64 VMs
